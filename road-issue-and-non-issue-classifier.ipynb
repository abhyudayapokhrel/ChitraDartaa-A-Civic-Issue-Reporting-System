{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14235341,"sourceType":"datasetVersion","datasetId":9081886},{"sourceId":14346697,"sourceType":"datasetVersion","datasetId":9160474},{"sourceId":694825,"sourceType":"modelInstanceVersion","modelInstanceId":526911,"modelId":540960}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y protobuf tensorflow\n\n!pip install protobuf==3.20.3 tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:17:07.215830Z","iopub.execute_input":"2026-01-16T13:17:07.216028Z","iopub.status.idle":"2026-01-16T13:18:08.195323Z","shell.execute_reply.started":"2026-01-16T13:17:07.216007Z","shell.execute_reply":"2026-01-16T13:18:08.194462Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: protobuf 5.29.5\nUninstalling protobuf-5.29.5:\n  Successfully uninstalled protobuf-5.29.5\nFound existing installation: tensorflow 2.19.0\nUninstalling tensorflow-2.19.0:\n  Successfully uninstalled tensorflow-2.19.0\nCollecting protobuf==3.20.3\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nCollecting tensorflow\n  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\nINFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n  Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\nRequirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\nRequirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (645.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, tensorflow\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngrain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.20.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.19.1 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3 tensorflow-2.19.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, Sequential\nfrom tensorflow.keras.utils import image_dataset_from_directory, load_img, img_to_array\nimport zipfile\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:18:08.197398Z","iopub.execute_input":"2026-01-16T13:18:08.197833Z","iopub.status.idle":"2026-01-16T13:18:16.559736Z","shell.execute_reply.started":"2026-01-16T13:18:08.197805Z","shell.execute_reply":"2026-01-16T13:18:16.559139Z"}},"outputs":[{"name":"stderr","text":"2026-01-16 13:18:08.791315: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768569488.813216      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768569488.819826      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768569488.837099      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768569488.837125      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768569488.837127      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768569488.837129      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#setting up important var for loading images later on\nBATCH_SIZE=32\nIMG_SIZE=(224,224)\nSEED=42\nEXTRACT_PATH=\"/kaggle/input/civic-issue-dataset/Dataset\"\nselected_class=[\"NoIssue\",\"Issues\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:18:16.560530Z","iopub.execute_input":"2026-01-16T13:18:16.560994Z","iopub.status.idle":"2026-01-16T13:18:16.564849Z","shell.execute_reply.started":"2026-01-16T13:18:16.560970Z","shell.execute_reply":"2026-01-16T13:18:16.564116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"#loading up images and dividing them for the neural net\ntrain_data=tf.keras.utils.image_dataset_from_directory(\n    EXTRACT_PATH,\n    class_names=selected_class,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"binary\" \n)\n\n#validation dataset\nvalidation_data=tf.keras.utils.image_dataset_from_directory(\n    EXTRACT_PATH,\n    class_names=selected_class,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"binary\"\n)\n#now dividing the validation data set into \ntotal_number_of_batches_in_validation_data=validation_data.cardinality().numpy() #converts total number of batches in the set and converts the tensor into python integer with .numpy function here\nno_of_batches_in_validation_data=total_number_of_batches_in_validation_data//2 #this is a floor division operator\n\n\n#now from the set of batches of the image creating subset into the validation and the test subset\nvalidation=validation_data.take(no_of_batches_in_validation_data)\ntest=validation_data.skip(no_of_batches_in_validation_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:18:16.565667Z","iopub.execute_input":"2026-01-16T13:18:16.565869Z","iopub.status.idle":"2026-01-16T13:19:17.919604Z","shell.execute_reply.started":"2026-01-16T13:18:16.565850Z","shell.execute_reply":"2026-01-16T13:19:17.918986Z"}},"outputs":[{"name":"stdout","text":"Found 19549 files belonging to 2 classes.\nUsing 15640 files for training.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1768569548.137231      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1768569548.141079      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Found 19549 files belonging to 2 classes.\nUsing 3909 files for validation.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#loading up images and dividing them for the neural net\ntrain_data=tf.keras.utils.image_dataset_from_directory(\n    EXTRACT_PATH,\n    class_names=selected_class,\n    validation_split=0.4,\n    subset=\"training\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"binary\" \n)\n\n#validation dataset\nvalidation_data=tf.keras.utils.image_dataset_from_directory(\n    EXTRACT_PATH,\n    class_names=selected_class,\n    validation_split=0.4,\n    subset=\"validation\",\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    label_mode=\"binary\"\n)\n#now dividing the validation data set into \ntotal_number_of_batches_in_validation_data=validation_data.cardinality().numpy() #converts total number of batches in the set and converts the tensor into python integer with .numpy function here\nno_of_batches_in_validation_data=total_number_of_batches_in_validation_data//2 #this is a floor division operator\n\n\n#now from the set of batches of the image creating subset into the validation and the test subset\nvalidation=validation_data.take(no_of_batches_in_validation_data)\ntest=validation_data.skip(no_of_batches_in_validation_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Class names: {train_data.class_names}\")\nprint(\"For values:\\n\")\nfor i, class_name in enumerate(train_data.class_names):\n    print(f\"{class_name}:{i}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:19:17.920890Z","iopub.execute_input":"2026-01-16T13:19:17.921492Z","iopub.status.idle":"2026-01-16T13:19:17.926216Z","shell.execute_reply.started":"2026-01-16T13:19:17.921463Z","shell.execute_reply":"2026-01-16T13:19:17.925334Z"}},"outputs":[{"name":"stdout","text":"Class names: ['NoIssue', 'Issues']\nFor values:\n\nNoIssue:0\n\nIssues:1\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#to augment data which we should do while training \ndata_augmentation=tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.15),\n    tf.keras.layers.RandomZoom(0.1),\n    tf.keras.layers.RandomContrast(0.1),\n    tf.keras.layers.GaussianNoise(0.05),\n    tf.keras.layers.RandomTranslation(0.1,0.1),\n    tf.keras.layers.RandomCrop(224,224),\n    tf.keras.layers.RandomBrightness(factor=0.2),\n    tf.keras.layers.RandomSaturation(0.05),\n    tf.keras.layers.RandomFlip(\"vertical\"),\n])\n\n#setting var to send for training to send info about input\ninput=tf.keras.Input(shape=(224,224,3))\n\n\n#now the acutal model which would be we want conv2d->pooling->conv2d->pooling->conv2d_>pooling-> flatten all the data two dense layer with relu\nmodel=tf.keras.Sequential([\n    input,\n    data_augmentation,\n    tf.keras.layers.Rescaling(1./255),\n\n#CNN LAYERS\n    tf.keras.layers.Conv2D(32,3,padding='same',activation=\"relu\"),\n    #here 32 is the number of filters/kernels, padding is same so it extends for the edges with 0 values and activation we chose is relu\n    tf.keras.layers.MaxPooling2D(),\n\n    tf.keras.layers.Conv2D(64,3, padding=\"same\",activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(),\n    \n    tf.keras.layers.Conv2D(128,3,padding=\"same\",activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(),\n\n    tf.keras.layers.Conv2D(256,3,padding=\"same\",activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(),\n\n    #now flatten this cube of input\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.5), #this makes the neural net to ignore 50 percent of the units all of the time so it would not look for same type of data everytime and prevent overfitting\n    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n])\n#now compile and fit them\nmodel.compile(optimizer=\"adam\",\n             loss=BinaryCrossentropy(from_logits=False),\n             metrics=[\"accuracy\",\n             tf.keras.metrics.Precision(name=\"Precision\"),\n             tf.keras.metrics.Recall(name=\"recall\"),])\nhistory=model.fit(\n    train_data,\n    validation_data=validation,\n    epochs=100,\n    callbacks=[\n        EarlyStopping(\n            monitor=\"val_accuracy\", #checks for val_accuracy\n            patience=5,#wait tills 5 epochs\n            restore_best_weights=True,#uses best weight\n        ),\n        ModelCheckpoint(\n            \"best_model.keras\",#givesbest model according to val_accuracy\n            monitor=\"val_accuracy\",\n            save_best_only=True,\n            verbose=1 #prints only certain line of epoch for 1 and for 0 is silence and for 2 is every line\n        )\n    ]\n)\n\n\ntest_loss,test_acc,test_precision,test_recall=model.evaluate(validation_data)\nprint(f\"Accuracy: {test_acc:4f}, Precision:{test_precision:.4f}, Recall:{test_recall:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:19:17.927299Z","iopub.execute_input":"2026-01-16T13:19:17.927544Z","iopub.status.idle":"2026-01-16T13:45:04.806547Z","shell.execute_reply.started":"2026-01-16T13:19:17.927523Z","shell.execute_reply":"2026-01-16T13:45:04.805819Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1768569565.517425     139 cuda_dnn.cc:529] Loaded cuDNN version 91002\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - Precision: 0.8026 - accuracy: 0.7994 - loss: 0.5399 - recall: 0.9949\nEpoch 1: val_accuracy improved from -inf to 0.80072, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 174ms/step - Precision: 0.8026 - accuracy: 0.7994 - loss: 0.5399 - recall: 0.9949 - val_Precision: 0.8011 - val_accuracy: 0.8007 - val_loss: 0.4176 - val_recall: 0.9994\nEpoch 2/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.8063 - accuracy: 0.8045 - loss: 0.4434 - recall: 0.9958\nEpoch 2: val_accuracy improved from 0.80072 to 0.80123, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - Precision: 0.8063 - accuracy: 0.8045 - loss: 0.4433 - recall: 0.9958 - val_Precision: 0.8027 - val_accuracy: 0.8012 - val_loss: 0.3930 - val_recall: 0.9974\nEpoch 3/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Precision: 0.8138 - accuracy: 0.8102 - loss: 0.4126 - recall: 0.9899\nEpoch 3: val_accuracy improved from 0.80123 to 0.89242, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - Precision: 0.8138 - accuracy: 0.8102 - loss: 0.4126 - recall: 0.9899 - val_Precision: 0.9071 - val_accuracy: 0.8924 - val_loss: 0.3059 - val_recall: 0.9649\nEpoch 4/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Precision: 0.8403 - accuracy: 0.8299 - loss: 0.3665 - recall: 0.9731\nEpoch 4: val_accuracy improved from 0.89242 to 0.91547, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - Precision: 0.8403 - accuracy: 0.8298 - loss: 0.3664 - recall: 0.9731 - val_Precision: 0.9169 - val_accuracy: 0.9155 - val_loss: 0.2618 - val_recall: 0.9833\nEpoch 5/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.8660 - accuracy: 0.8586 - loss: 0.3135 - recall: 0.9749\nEpoch 5: val_accuracy improved from 0.91547 to 0.93443, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.8660 - accuracy: 0.8587 - loss: 0.3135 - recall: 0.9749 - val_Precision: 0.9405 - val_accuracy: 0.9344 - val_loss: 0.2101 - val_recall: 0.9802\nEpoch 6/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.8943 - accuracy: 0.8801 - loss: 0.3073 - recall: 0.9647\nEpoch 6: val_accuracy improved from 0.93443 to 0.93648, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - Precision: 0.8943 - accuracy: 0.8802 - loss: 0.3073 - recall: 0.9647 - val_Precision: 0.9327 - val_accuracy: 0.9365 - val_loss: 0.1993 - val_recall: 0.9923\nEpoch 7/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9138 - accuracy: 0.9007 - loss: 0.2616 - recall: 0.9675\nEpoch 7: val_accuracy did not improve from 0.93648\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.9138 - accuracy: 0.9007 - loss: 0.2616 - recall: 0.9675 - val_Precision: 0.9568 - val_accuracy: 0.9365 - val_loss: 0.1911 - val_recall: 0.9641\nEpoch 8/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9175 - accuracy: 0.9058 - loss: 0.2603 - recall: 0.9694\nEpoch 8: val_accuracy did not improve from 0.93648\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.9175 - accuracy: 0.9058 - loss: 0.2603 - recall: 0.9694 - val_Precision: 0.9335 - val_accuracy: 0.9349 - val_loss: 0.1964 - val_recall: 0.9891\nEpoch 9/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9247 - accuracy: 0.9117 - loss: 0.2467 - recall: 0.9689\nEpoch 9: val_accuracy did not improve from 0.93648\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 116ms/step - Precision: 0.9247 - accuracy: 0.9117 - loss: 0.2467 - recall: 0.9689 - val_Precision: 0.9660 - val_accuracy: 0.9308 - val_loss: 0.1922 - val_recall: 0.9469\nEpoch 10/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9309 - accuracy: 0.9130 - loss: 0.2379 - recall: 0.9632\nEpoch 10: val_accuracy improved from 0.93648 to 0.93750, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.9309 - accuracy: 0.9130 - loss: 0.2379 - recall: 0.9632 - val_Precision: 0.9461 - val_accuracy: 0.9375 - val_loss: 0.1902 - val_recall: 0.9776\nEpoch 11/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9338 - accuracy: 0.9159 - loss: 0.2295 - recall: 0.9633\nEpoch 11: val_accuracy improved from 0.93750 to 0.94518, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 125ms/step - Precision: 0.9339 - accuracy: 0.9159 - loss: 0.2295 - recall: 0.9633 - val_Precision: 0.9624 - val_accuracy: 0.9452 - val_loss: 0.1705 - val_recall: 0.9692\nEpoch 12/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9398 - accuracy: 0.9237 - loss: 0.2098 - recall: 0.9668\nEpoch 12: val_accuracy did not improve from 0.94518\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.9398 - accuracy: 0.9237 - loss: 0.2098 - recall: 0.9668 - val_Precision: 0.9779 - val_accuracy: 0.9098 - val_loss: 0.2284 - val_recall: 0.9076\nEpoch 13/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9388 - accuracy: 0.9223 - loss: 0.2095 - recall: 0.9660\nEpoch 13: val_accuracy improved from 0.94518 to 0.94723, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 125ms/step - Precision: 0.9388 - accuracy: 0.9223 - loss: 0.2095 - recall: 0.9660 - val_Precision: 0.9626 - val_accuracy: 0.9472 - val_loss: 0.1517 - val_recall: 0.9718\nEpoch 14/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9409 - accuracy: 0.9250 - loss: 0.2009 - recall: 0.9672\nEpoch 14: val_accuracy improved from 0.94723 to 0.94775, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 117ms/step - Precision: 0.9409 - accuracy: 0.9250 - loss: 0.2010 - recall: 0.9672 - val_Precision: 0.9603 - val_accuracy: 0.9477 - val_loss: 0.1540 - val_recall: 0.9750\nEpoch 15/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - Precision: 0.9426 - accuracy: 0.9277 - loss: 0.2042 - recall: 0.9688\nEpoch 15: val_accuracy did not improve from 0.94775\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - Precision: 0.9426 - accuracy: 0.9277 - loss: 0.2042 - recall: 0.9688 - val_Precision: 0.9589 - val_accuracy: 0.9467 - val_loss: 0.1479 - val_recall: 0.9749\nEpoch 16/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - Precision: 0.9436 - accuracy: 0.9269 - loss: 0.1941 - recall: 0.9666\nEpoch 16: val_accuracy did not improve from 0.94775\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 121ms/step - Precision: 0.9436 - accuracy: 0.9269 - loss: 0.1941 - recall: 0.9666 - val_Precision: 0.9650 - val_accuracy: 0.9457 - val_loss: 0.1509 - val_recall: 0.9674\nEpoch 17/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9443 - accuracy: 0.9294 - loss: 0.1990 - recall: 0.9690\nEpoch 17: val_accuracy improved from 0.94775 to 0.94980, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 116ms/step - Precision: 0.9443 - accuracy: 0.9293 - loss: 0.1990 - recall: 0.9690 - val_Precision: 0.9487 - val_accuracy: 0.9498 - val_loss: 0.1406 - val_recall: 0.9911\nEpoch 18/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - Precision: 0.9448 - accuracy: 0.9324 - loss: 0.1845 - recall: 0.9723\nEpoch 18: val_accuracy did not improve from 0.94980\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 116ms/step - Precision: 0.9448 - accuracy: 0.9324 - loss: 0.1845 - recall: 0.9723 - val_Precision: 0.9783 - val_accuracy: 0.9216 - val_loss: 0.1947 - val_recall: 0.9226\nEpoch 19/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9482 - accuracy: 0.9318 - loss: 0.1812 - recall: 0.9681\nEpoch 19: val_accuracy did not improve from 0.94980\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 115ms/step - Precision: 0.9482 - accuracy: 0.9318 - loss: 0.1812 - recall: 0.9681 - val_Precision: 0.9624 - val_accuracy: 0.9447 - val_loss: 0.1507 - val_recall: 0.9686\nEpoch 20/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Precision: 0.9498 - accuracy: 0.9322 - loss: 0.1921 - recall: 0.9665\nEpoch 20: val_accuracy did not improve from 0.94980\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 114ms/step - Precision: 0.9498 - accuracy: 0.9322 - loss: 0.1921 - recall: 0.9665 - val_Precision: 0.9775 - val_accuracy: 0.9349 - val_loss: 0.1788 - val_recall: 0.9408\nEpoch 21/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9474 - accuracy: 0.9332 - loss: 0.1914 - recall: 0.9707\nEpoch 21: val_accuracy improved from 0.94980 to 0.95645, saving model to best_model.keras\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 116ms/step - Precision: 0.9474 - accuracy: 0.9332 - loss: 0.1914 - recall: 0.9707 - val_Precision: 0.9641 - val_accuracy: 0.9565 - val_loss: 0.1399 - val_recall: 0.9820\nEpoch 22/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9479 - accuracy: 0.9334 - loss: 0.1796 - recall: 0.9703\nEpoch 22: val_accuracy did not improve from 0.95645\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 115ms/step - Precision: 0.9478 - accuracy: 0.9334 - loss: 0.1796 - recall: 0.9703 - val_Precision: 0.9703 - val_accuracy: 0.9477 - val_loss: 0.1466 - val_recall: 0.9641\nEpoch 23/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9505 - accuracy: 0.9362 - loss: 0.1729 - recall: 0.9708\nEpoch 23: val_accuracy did not improve from 0.95645\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 115ms/step - Precision: 0.9505 - accuracy: 0.9362 - loss: 0.1729 - recall: 0.9708 - val_Precision: 0.9620 - val_accuracy: 0.9483 - val_loss: 0.1410 - val_recall: 0.9737\nEpoch 24/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - Precision: 0.9489 - accuracy: 0.9347 - loss: 0.1733 - recall: 0.9708\nEpoch 24: val_accuracy did not improve from 0.95645\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 115ms/step - Precision: 0.9489 - accuracy: 0.9347 - loss: 0.1733 - recall: 0.9708 - val_Precision: 0.9876 - val_accuracy: 0.8914 - val_loss: 0.2414 - val_recall: 0.8745\nEpoch 25/100\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - Precision: 0.9526 - accuracy: 0.9379 - loss: 0.1707 - recall: 0.9710\nEpoch 25: val_accuracy did not improve from 0.95645\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 115ms/step - Precision: 0.9526 - accuracy: 0.9379 - loss: 0.1707 - recall: 0.9710 - val_Precision: 0.9800 - val_accuracy: 0.9401 - val_loss: 0.1660 - val_recall: 0.9442\nEpoch 26/100\n\u001b[1m488/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - Precision: 0.9553 - accuracy: 0.9422 - loss: 0.1661 - recall: 0.9735\nEpoch 26: val_accuracy did not improve from 0.95645\n\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 114ms/step - Precision: 0.9553 - accuracy: 0.9422 - loss: 0.1661 - recall: 0.9735 - val_Precision: 0.9799 - val_accuracy: 0.9314 - val_loss: 0.1729 - val_recall: 0.9335\n\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 122ms/step - Precision: 0.9662 - accuracy: 0.9553 - loss: 0.1327 - recall: 0.9782\nAccuracy: 0.958557, Precision:0.9687, Recall:0.9799\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"For accuracy:\n1) We have total of 15.6k  images of issues and 3954 images of non-issues and total of 19549 images.\n2) For threshold accuracy we take a very dumb modal that would always predict the class with higher images so which would be:\n       threshold_accuracy=(15640/19549)*100=80.004%\n3) However, we do need to figure out recall and precision values which we take harmonic mean of must be >=0.65\n   NOTE: Why do we take recall and precision here?\n   => We do it because we have unbalanced data not only we need accurate value we need values with good precision and recall value where,<br>\n   precision=(True positive values(values we predicted positive and is positive))/(No of True values we predict(both false and true positive))<br>\n   recall=(true +ve(no of predicted=actual true)/Total actual positive value(both true positive we predict and false negative we predict))","metadata":{}},{"cell_type":"markdown","source":"## For training exp1:\n1) We have validation of 20% data shuffled\n2) 4 layers of cnn\n   All the metrics have:\n   a) accuracy=96.07\n   b) precision=97.26\n   c) recall=97.82\n\n## For tranining exp2:\n1) We have validation of 40% data shuffled\n2) 4 layers of cnn\n   All the metrics have:\n   a) accuracy=\n   b) precision=\n   c) recall=\n","metadata":{}},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/models\",exist_ok=True)\nmodel.save(\"/kaggle/working/models/pothole_model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:26:32.791322Z","iopub.execute_input":"2026-01-01T14:26:32.791630Z","iopub.status.idle":"2026-01-01T14:26:33.130323Z","shell.execute_reply.started":"2026-01-01T14:26:32.791605Z","shell.execute_reply":"2026-01-01T14:26:33.129372Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result=model.evaluate(test)\nprint(f\"For the unseen test data of the entire training this model has accuracy of {result[1]:.4f}, precision of {result[2]:.4f}, and recall of {result[3]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:45:04.810614Z","iopub.execute_input":"2026-01-16T13:45:04.810860Z","iopub.status.idle":"2026-01-16T13:45:16.844612Z","shell.execute_reply.started":"2026-01-16T13:45:04.810839Z","shell.execute_reply":"2026-01-16T13:45:16.844006Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - Precision: 0.9742 - accuracy: 0.9676 - loss: 0.1100 - recall: 0.9853\nFor the unseen test data of the entire training this model has accuracy of 0.9607, precision of 0.9726, and recall of 0.9782\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T13:45:30.425907Z","iopub.execute_input":"2026-01-16T13:45:30.426556Z","iopub.status.idle":"2026-01-16T13:45:30.448373Z","shell.execute_reply.started":"2026-01-16T13:45:30.426528Z","shell.execute_reply":"2026-01-16T13:45:30.447708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m6,422,656\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,656</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,433,605\u001b[0m (77.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,433,605</span> (77.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,811,201\u001b[0m (25.98 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,811,201</span> (25.98 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m13,622,404\u001b[0m (51.97 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,622,404</span> (51.97 MB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Harmonic mean we got is 0.95855 which is a very good value for the data","metadata":{}},{"cell_type":"code","source":"def predict_for_single_image(model, img_path):\n    img=tf.keras.utils.load_img(img_path, target_size=(224,224))\n    img_array=tf.keras.utils.img_to_array(img)\n    img_array=np.expand_dims(img_array, axis=0)\n    prediction=model.predict(img_array)\n    probability=prediction[0][0]\n    if probability>0.5:\n        return 1;\n    return 0;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:02.461354Z","iopub.execute_input":"2026-01-01T14:25:02.461619Z","iopub.status.idle":"2026-01-01T14:25:02.466158Z","shell.execute_reply.started":"2026-01-01T14:25:02.461597Z","shell.execute_reply":"2026-01-01T14:25:02.465625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#to load up images\nprint(f\"For i1 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/i1.png\")}\")\nprint(f\"For i11 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/i11.jpeg\")}\")\nprint(f\"For i2 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/i2.png\")}\")\nprint(f\"For i3 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/i3.png\")}\")\nprint(f\"For n1 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/n1.jpg\")}\")\nprint(f\"For n2 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/n2.jpg\")}\")\nprint(f\"For n3 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/n3.png\")}\")\nprint(f\"For n4 we got {predict_for_single_image(model, \"/kaggle/input/helpppp/helppp/n4.jpeg\")}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:02.466894Z","iopub.execute_input":"2026-01-01T14:25:02.467181Z","iopub.status.idle":"2026-01-01T14:25:03.746221Z","shell.execute_reply.started":"2026-01-01T14:25:02.467152Z","shell.execute_reply":"2026-01-01T14:25:03.745628Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the folder for easy download\nshutil.make_archive(\"/kaggle/working/models\", 'zip', \"/kaggle/working/models\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:03.747105Z","iopub.execute_input":"2026-01-01T14:25:03.747381Z","iopub.status.idle":"2026-01-01T14:25:08.224247Z","shell.execute_reply.started":"2026-01-01T14:25:03.747359Z","shell.execute_reply":"2026-01-01T14:25:08.223635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#this is to see what our model did and how it is predicting\ndef visualisation(model,dataset,num_images=32):\n    images, label=next(iter(dataset.take(1))) #take 1 takes one batch from tensorflow data set\n    #where (image, 0 or 1) and this is returned as ptr or itr and next just gives access to it\n    #following model is trained model as above\n    pred=model.predict(images)\n    plt.figure(figsize=(90,80))#image with 15 inches height and 10 inches width\n\n    #randomly taking images\n    indices=np.random.choice(range(len(images)),num_images,replace=False)\n    #this randomly takes images from total number of images with replace=false so no duplicate images will be passes\n    \n\n    for i, idx in enumerate(indices):\n        ax=plt.subplot(8,4,i+1) #creating subplot of 8*4 grid\n        #converting images into the original scale as we rescale it into the image\n        plt.imshow(images[idx].numpy().astype(\"uint8\"))#displays image by converting first tensor into pixel values and then uint8 ie 0-255 \n        actual_val=int(label[idx])\n        predicted_val=1 if pred[idx]>0.5 else 0\n        color =\"green\" if actual_val==predicted_val else \"red\"\n        title=f\"Actual:{actual_val}\\nPredicted:{predicted_val}\"\n        plt.title(title,color=color,fontsize=40,fontweight=\"bold\")\n        plt.axis(\"off\")\n\n    #adding horizontal and vertical spaces between plots\n    plt.subplots_adjust(hspace=0.6,wspace=0.3)\n    plt.tight_layout\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:08.225172Z","iopub.execute_input":"2026-01-01T14:25:08.225417Z","iopub.status.idle":"2026-01-01T14:25:08.231536Z","shell.execute_reply.started":"2026-01-01T14:25:08.225396Z","shell.execute_reply":"2026-01-01T14:25:08.230976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#seeing how model predicted for different images\nvisualisation(model,train_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:08.232268Z","iopub.execute_input":"2026-01-01T14:25:08.232488Z","iopub.status.idle":"2026-01-01T14:25:15.213575Z","shell.execute_reply.started":"2026-01-01T14:25:08.232457Z","shell.execute_reply":"2026-01-01T14:25:15.212303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualisation(model,validation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:15.215165Z","iopub.execute_input":"2026-01-01T14:25:15.215411Z","iopub.status.idle":"2026-01-01T14:25:21.780642Z","shell.execute_reply.started":"2026-01-01T14:25:15.215386Z","shell.execute_reply":"2026-01-01T14:25:21.779394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualisation(model,test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T14:25:21.782004Z","iopub.execute_input":"2026-01-01T14:25:21.782313Z","iopub.status.idle":"2026-01-01T14:25:34.967907Z","shell.execute_reply.started":"2026-01-01T14:25:21.782289Z","shell.execute_reply":"2026-01-01T14:25:34.966453Z"}},"outputs":[],"execution_count":null}]}